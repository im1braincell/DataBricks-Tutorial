{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b053155e-bbbc-430c-a2d8-9a6d7cea1a6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Stream-Stream Joins using Structured Streaming (Python)\n",
    "This notebook illustrates different ways of joining streams.\n",
    "\n",
    "We are going to use the the canonical example of ad monetization, where we want to find out which ad impressions led to user clicks. \n",
    "Typically, in such scenarios, there are two streams of data from different sources - ad impressions and ad clicks. \n",
    "Both type of events have a common ad identifier (say, `adId`), and we want to match clicks with impressions based on the `adId`. \n",
    "In addition, each event also has a timestamp, which we will use to specify additional conditions in the query to limit the streaming state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de94894e-7c4e-464b-9dd0-cbdadad873f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Disclaimer** : Notebook นี้มาจาก [official docs ของ databricks](https://docs.databricks.com/aws/en/structured-streaming/examples#stream-stream-joins) ค่ะ อาจมีการปรับปรุงเปลี่ยนแปลงเล็กน้อยให้เข้ากับ free edition ในปัจจุบัน และอธิบายภาษาไทยตามความเข้าใจค่ะ\n",
    " \n",
    "> Notebook นี้จะแสดงให้เราเห็นวิธี(ตั่งต่าง)ในการเชื่อม stream เข้าด้วยกัน\n",
    "> \n",
    "> โดยใช้ตัวอย่างเป็นเรื่องของการสร้างรายได้จากการโฆษณา ซึ่งเราก็จะต้องหาว่า โฆษณาไหนที่ดึงดูดใจให้ลูกค้าคลิก\n",
    "> \n",
    "> ในสถานการณ์แบบนี้ จะมีข้อมูลไหลมาจาก sources ที่ต่างกัน 2 sources คือ\n",
    "> - ad impressions\n",
    "> - ad clicks\n",
    "> \n",
    "> และทั้ง events ทั้ง 2 อันนี้มีสิ่งระบุตัวของโฆษณาที่เหมือนกัน (`adId`) ดังนั้นเราก็ต้อง match clicks & impressions โดยใช้ `adId`\n",
    "> \n",
    "> นอกจากนี้ ในแต่ละ event จะมี timestamp อยู่ด้วย ซึ่งจะใช้ระบุเงื่อนไขใน query เพื่อจะได้จำกัดตัว state ของการ stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0398049-bee6-4424-8cb6-c9cac059692b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In absence of actual data streams, we are going to generate fake data streams using our built-in \"rate stream\", that generates data at a given fixed rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c17f40d-8003-4234-9115-2f4e8382ef74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> ในกรณีนี้ที่เราไม่ได้มีข้อมูลจริง เราก็จะสร้างข้อมูลปลอมขึ้นมาโดยใช้ built-in 'rate stream' ซึ่งจะสร้างข้อมูลขึ้นมาใน rate ที่เรากำหนดไว้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac7c033b-f9ec-4a0a-b661-305262dd7a4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"1\")\n",
    "\n",
    "impressions = (\n",
    "  spark\n",
    "    .readStream.format(\"rate\").option(\"rowsPerSecond\", \"5\").option(\"numPartitions\", \"1\").load()\n",
    "    .selectExpr(\"value AS adId\", \"timestamp AS impressionTime\")\n",
    ")\n",
    "\n",
    "clicks = (\n",
    "  spark\n",
    "  .readStream.format(\"rate\").option(\"rowsPerSecond\", \"10\").option(\"numPartitions\", \"1\").load()\n",
    "  .where((rand() * 100).cast(\"integer\") < 10)      # 10 out of every 100 impressions result in a click\n",
    "  .selectExpr(\"(value-50) AS adId \", \"timestamp AS clickTime\")\n",
    "  # -50 so that a click with same id as impression is generated later (i.e. delayed data).\n",
    "  .where(\"adId > 0\")\n",
    ")    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2a8dfcf-0264-46af-a4e7-25e1abdcc95b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's see what data these two streaming DataFrames generate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bf099c4-40c9-4225-b8f1-472c23e6f3ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> มาดูข้อมูลกันจ้ะ (แน่นอนว่า การจะ display ข้อมูลต้องมี checkpoint (อีกแล้ว) และไม่ใช่ checkpoint แบบซ้ำกัน เลยใช้การแก้ปัญหาเฉพาะหน้าเช่นเดิมด้วยการใช้ uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0351bd8-a02e-4d76-8026-d6ecc2719956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "path = f\"/Volumes/workspace/default/tutorial/testssetc/ststj_{uuid.uuid4()}\"\n",
    "\n",
    "display(impressions, checkpointLocation=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04da1d5c-4434-4fc9-a465-1a641ecb1685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> ถ้าไม่เห็นข้อมูลส่วนนี้ออกมา ไม่ต้องตกใจ มาจาก logic ข้างบน (เพราะตอนแรกผู้ทดลองตกใจไปแล้วค่ะ555) \n",
    "\n",
    "logic คือ\n",
    "- เราใช้เงื่อนไขตรง where ว่า `(rand() * 100).cast(\"integer\") < 10` คือการสุ่มเลขมา และเลขที่สุ่มมาต้องน้อยกว่า 10 ด้วย ดังนั้นการสุ่มแบบนี้ก็เป็นเหมือนสุ่มกาชาหาเลขที่น้อยกว่า 10 เพื่อจะบอกว่าจะเก็บข้อมูลแต่ละแถวมั้ย ถ้าในแถวนั้นถูกสุ่มเลขมาแล้วเลขที่ได้มีค่าตั้งแต่ 10 ขึ้นไป = ทิ้งแถวนั้นไป (เหมือนที่เขาระบุใน cell ไว้ประมาณว่า จากทุก 100 impressions จะมีประมาณ 10 ที่นำไปสู่การ click ซึ่งก็สร้างสถานการณ์ให้มีความใกล้เคียงความเป็นจริง)\n",
    "- การใช้ `value-50` เป็น `adId` มันจะสร้างข้อมูล 0-50, 1-50, 2-50,... ไปเรื่อยๆ นั่นแปลว่า มันจะครบ 50-50 ในจบวินาทีที่ 5 ถึงจะมีเริ่ม adId ออกมาในวินาทีที่ 6\n",
    "\n",
    "จาก 2 ข้อนี้ทำให้ข้อมูลออกมาน้อยสะบัด และจาก path ที่ใช้บันทึก checkpoint รวมไปถึงข้อจำกัดต่างๆนานาของตัว free edition ที่ทำให้เราต้องใช้ volume มาเก็บข้อมูล เลยทำให้การรันโค้ด display impressions ใช้เวลาติ๊ดเดียว พอใช้เวลาติ๊ดเดียว ในส่วน clicks ก็ยังไม่ทันจะมีข้อมูลให้ใช้ เราเลยไม่เห็นข้อมูล T-T\n",
    "\n",
    "ถ้าอยากเห็นข้อมูลสามารถแก้ logic ข้างบนได้!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04e7ba32-3907-48c2-b763-4a2a55329f3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = f'/Volumes/workspace/default/tutorial/testssetc/ststj{uuid.uuid4()}'\n",
    "display(clicks, checkpointLocation=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f57719a-d74f-41f7-94d8-5bc45c2c6bf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note: \n",
    "- If you get an error saying the join is not supported, the problem may be that you are running this notebook in an older version of Spark. \n",
    "- If you are running on Community Edition, click Cancel above to stop the streams, as you do not have enough cores to run many streams simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fc3d1af-9aff-4e93-b0cf-426e04741e0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Notes เพิ่มเติมจาก official\n",
    "> - ถ้าได้ error ที่บอกว่าการ join ไม่ support มันแปลว่าเราใช้ spark ที่เก่าใน notebook นี้\n",
    "> - ถ้าใช้บน community edition ให้ cencel เพื่อหยุด stream ด้วย เนื่องจาก core ของเราไม่พอที่จะใช้ stream หลายๆอันพร้อมกัน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "943e5bca-07af-430e-abc2-23a7d03ed51c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Inner Join\n",
    "\n",
    "Let's join these two data streams. This is exactly the same as joining two batch DataFrames/Datasets by their common key `adId`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e4c8c4e-39d1-432e-8cea-3527dbf9ffd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> มาลองจอย 2 streams เข้าด้วยกันดู ซึ่งการ join ก็จะเหมือนกันกับการ join DF, Datasets (batch) โดยใช้คีย์ที่เหมือนกัน คือ `adId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0e33f52-b286-4338-9dde-aadfa579d3b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = f'/Volumes/workspace/default/tutorial/testssetc/ststj{uuid.uuid4()}'\n",
    "\n",
    "display(impressions.join(clicks, \"adId\"), checkpointLocation=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd5aad04-76bb-44d3-a76b-43ded3bce93c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "After you start this query, within a minute, you will start getting joined impressions and clicks. The delays of a minute is due to the fact that clicks are being generated with delay over the corresponding impressions.\n",
    "\n",
    "In addition, if you expand the details of the query above, you will find a few timelines of query metrics - the processing rates, the micro-batch durations, and the size of the state. \n",
    "If you keep running this query, you will notice that the state will keep growing in an unbounded manner. This is because the query must buffer all past input as any new input can match with any input from the past. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a09e727c-fb90-4a36-9a5e-d5325bf4e726",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> หลังรัน query เพื่อ join ไปแล้วไม่นาน เราจะเริ่มเห็นข้อมูลที่มัน join กันของ impressions & clicks ซึ่งการที่เราต้องรอมันมาจาก delay ที่เราวางยาไว้\n",
    "\n",
    "> ถ้าเราเปิดดูรายละเอียดของ query จะเห็น timeline พวก processing rate, ระยะเวลาที่ใช้ในแต่ละ micro-batch และ size ของ state\n",
    "\n",
    "> การปล่อยให้ query มันรันไปเรื่อยๆ จะเห็นว่า state มันจะโตขึ้นเรื่อยๆ เพราะ query มันจะเก็บข้อมูลเก่าไว้ match กับข้อมูลใหม่ๆที่ไหลเข้ามา\n",
    "\n",
    "(แต่ในเคสของเรา จะไม่ได้เห็นความเปลี่ยนแปลงตรงนี้)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af40588b-58af-4ecf-9b58-ada4edc58a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Inner Join with Watermarking\n",
    "\n",
    "To avoid unbounded state, you have to define additional join conditions such that indefinitely old inputs cannot match with future inputs and therefore can be cleared from the state. In other words, you will have to do the following additional steps in the join.\n",
    "\n",
    "1. Define watermark delays on both inputs such that the engine knows how delayed the input can be. \n",
    "\n",
    "1. Define a constraint on event-time across the two inputs such that the engine can figure out when old rows of one input is not going to be required (i.e. will not satisfy the time constraint) for matches with the other input. This constraint can be defined in one of the two ways.\n",
    "\n",
    "  a. Time range join conditions (e.g. `...JOIN ON leftTime BETWEN rightTime AND rightTime + INTERVAL 1 HOUR`),\n",
    "  \n",
    "  b. Join on event-time windows (e.g. `...JOIN ON leftTimeWindow = rightTimeWindow`).\n",
    "\n",
    "Let's apply these steps to our use case. \n",
    "\n",
    "1. Watermark delays: Say, the impressions and the corresponding clicks can be delayed/late in event-time by at most \"10 seconds\" and \"20 seconds\", respectively. This is specified in the query as watermarks delays using `withWatermark`.\n",
    "\n",
    "1. Event-time range condition: Say, a click can occur within a time range of 0 seconds to 1 minute after the corresponding impression. This is specified in the query as a join condition between `impressionTime` and `clickTime`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9ae8636-98dc-4332-b722-66acd1386e45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> เพื่อป้องกัน unbounded state เราจะต้องระบุเงื่อนไขในการ join เพิ่มเติม เพื่อไม่ให้ input เก่า(เกินไป)กะ input ใหม่(ในอนาคต) join กันได้แบบไม่จำกัดเวลา ละจะได้ clear จาก state หรือเอาง่ายๆคือเราสรุปว่ามี 2 ข้อเพิ่มเติมที่ต้องทำ คือ\n",
    "1. ระบุลายน้ำ(?) Watermark การ delay ในทั้ง 2 input เพื่อให้ engine รู้ว่าข้อมูลที่เข้ามาจะ delay กันได้เท่าไหร่ยังไง\n",
    "2. ระบุเงื่อนไขเวลาที่ engine มันจะตัดว่าแถวๆนี้ในข้อมูลชุดนึงไม่ได้จำเป็นที่จะเอามาใช้งานเพื่อ match กับข้อมูลอีกชุดแล้ว ซึ่งจะสามารถระบุได้ 2 แบบ\n",
    "    - Time range join (ช่วงเวลา) : มองว่าเป็นเวลาเท่านี้ๆ คลาดกันได้ไม่เกินเท่านี้\n",
    "    - กรอบช่วงเวลาตาม events (window) : มองเป็นกล่อง เป็นกรอบ ถ้าอยู่ในกรอบนี้คือ join คนละกรอบต่อให้เวลาห่างกันนิดเดียวก็ไม่ join\n",
    "\n",
    "> Our Use Case\n",
    "1. Watermark delays : impressions หน่วงได้ 10 วิ, clicks หน่วงได้ 20 วิ ระบุใน query โดยใช้ `withWatermark`\n",
    "2. Event-time range : เราใช้เงื่อนไขเวลาแบบแรก ที่ใช้เป็นช่วงของเวลา คือ 1 คลิก สามารถเกิดขึ้นได้ใน range 0 วิ - 1 นาที **หลัง**จากที่ดูตัวโฆษณา ตรงนี้จะเป็นเงื่อนไขที่ใช้ระบุช่วงเวลาระหว่าง `impressionTime` and `clickTime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5ef54c1-14e2-426b-9bec-9982a35bd477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Define watermarks\n",
    "impressionsWithWatermark = impressions \\\n",
    "  .selectExpr(\"adId AS impressionAdId\", \"impressionTime\") \\\n",
    "  .withWatermark(\"impressionTime\", \"10 seconds \")\n",
    "clicksWithWatermark = clicks \\\n",
    "  .selectExpr(\"adId AS clickAdId\", \"clickTime\") \\\n",
    "  .withWatermark(\"clickTime\", \"20 seconds\")        # max 20 seconds late\n",
    "\n",
    "path = f'/Volumes/workspace/default/tutorial/testssetc/ststj{uuid.uuid4()}'\n",
    "# Inner join with time range conditions\n",
    "display(\n",
    "  impressionsWithWatermark.join(\n",
    "    clicksWithWatermark,\n",
    "    expr(\"\"\" \n",
    "      clickAdId = impressionAdId AND \n",
    "      clickTime >= impressionTime AND \n",
    "      clickTime <= impressionTime + interval 1 minutes    \n",
    "      \"\"\"\n",
    "    )\n",
    "  ), checkpointLocation=path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7826dcf-45c6-456b-a010-cc10a5ec81e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We are getting the similar results as the previous simple join query. However, if you look at the query metrics now, you will find that after about a couple of minutes of running the query, the size of the state will stabilize as the old buffered events will start getting cleared up.\n",
    "\n",
    "> เราอาจจะเห็นว่ามันได้ผลลัพธ์แบบเดียวกันกับการ join แรกที่เราลองไป แต่ว่าถ้าไปดู detail เพิ่มเติมของ query เราจะเห็นว่าขนาดของ state ค่อนข้างจะคงที่ เพราะว่ามีการเคลียร์เหตุการณ์เก่าๆถูก clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9122fd19-5682-4714-93ec-806e04ef446c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Outer Joins with Watermarking \n",
    "\n",
    "Let's extend this use case to illustrate outer joins. Not all ad impressions will lead to clicks and you may want to keep track of impressions that did not produce clicks. This can be done by applying a left outer join on the impressions and clicks. The joined output will not have the matched clicks, but also the unmatched ones (with clicks data being NULL).\n",
    "\n",
    "While the watermark + event-time constraints is optional for inner joins, for left and right outer joins they must be specified. This is because for generating the NULL results in outer join, the engine must know when an input row is not going to match with anything in future. Hence, the watermark + event-time constraints must be specified for generating correct results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72523131-c6bc-4d73-ba25-c40027cc8058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> use case เพิ่มเติมของกรณีนี้ที่เหมาะที่ใช้ในการ join คือ outer join เพราะว่าไม่ใช่ทุก ads ที่จะมี click และเราก็อยากรู้อยากเห็นอยากจะ track ตัว ad พวกนี้ด้วยเช่นกัน เราจะใช้ left outer join ซึ่งจะมีทั้งการ click ที่ match กับ impressions และที่ไม่ match จะแสดงผล clicks เป็น null\n",
    "\n",
    "> ในขณะที่ watermark และ event-time constraints เป็นเงื่อนไขที่จะมีหรือไม่มีก็ได้ใน inner joins แต่ว่า การระบุ 2 อย่างนี้ ต้องมีการระบุใน outer join เพราะว่าการที่ engine จะแสดงผล null ใน outer join ได้นั้น เจ้าตัว engine จะต้องรู้ว่า input แถวไหนที่เข้ามามันไม่ได้ match กับอะไรเลย เพื่อจะได้แสดงผลให้ถูกต้องนั่นเอง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a7975ff-42de-4462-89bf-0a9d165894bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "path = f'/Volumes/workspace/default/tutorial/testssetc/ststj{uuid.uuid4()}'\n",
    "# Inner join with time range conditions\n",
    "display(\n",
    "  impressionsWithWatermark.join(\n",
    "    clicksWithWatermark,\n",
    "    expr(\"\"\" \n",
    "      clickAdId = impressionAdId AND \n",
    "      clickTime >= impressionTime AND \n",
    "      clickTime <= impressionTime + interval 1 minutes    \n",
    "      \"\"\"\n",
    "    ),\n",
    "    \"leftOuter\"\n",
    "  ), checkpointLocation=path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20fff4e8-4e6a-4e55-955b-bcc90aceb1a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "After starting this query, you will start getting the inner results within a minute. But after a couple of minutes, you will also start getting the outer NULL results.\n",
    "\n",
    "> หลังจากรัน query นี้ เราจะได้ผลให้ดูภายในเวลาสั้นๆ แต่หลังจากนั้นอีกประมาณ 2 นาที ถึงจะเริ่มเห็นผลที่มีค่า null ด้วย"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6cea052-eecb-4851-a255-3f5ca1958f20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Further Information\n",
    "You can read more about stream-stream joins in the following places:\n",
    "\n",
    "- Databricks blog post on stream-stream joins - https://databricks.com/blog/2018/03/13/introducing-stream-stream-joins-in-apache-spark-2-3.html\n",
    "- Apache Programming Guide on Structured Streaming - https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#stream-stream-joins\n",
    "- Talk at Spark Summit Europe 2017 - https://databricks.com/session/deep-dive-into-stateful-stream-processing-in-structured-streaming\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7819308743381951,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "stream-stream-joins-python",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
